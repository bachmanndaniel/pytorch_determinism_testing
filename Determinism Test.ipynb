{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caceb394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import trimesh\n",
    "\n",
    "import math\n",
    "from math import sqrt\n",
    "import random\n",
    "\n",
    "#mind import order\n",
    "from mesh_to_sdf import get_surface_point_cloud\n",
    "from mesh_to_sdf.utils import sample_uniform_points_in_unit_sphere\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl' #opengl seems to only work with TPU\n",
    "!PYOPENGL_PLATFORM=egl python -c 'from OpenGL import EGL'\n",
    "print(os.environ['PYOPENGL_PLATFORM'])\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb2c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_features = hidden_features\n",
    "        self.layers = []\n",
    "        \n",
    "        #input layer\n",
    "        self.layers += [nn.Linear(in_features, hidden_features), nn.LeakyReLU(0.1)]\n",
    "\n",
    "        #hidden layers\n",
    "        for i in range(hidden_layers):\n",
    "          self.layers += [nn.Linear(hidden_features, hidden_features), nn.LeakyReLU(0.1)]\n",
    "\n",
    "        #output layer\n",
    "        self.layers += [nn.Linear(hidden_features, out_features)]\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        #output = torch.sigmoid(self.layers(coords))\n",
    "        output = self.layers(coords)\n",
    "        return output\n",
    "    \n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, nn.Linear):\n",
    "                weights.append(l.weight.data.detach())\n",
    "        return weights\n",
    "                \n",
    "    def biases(self):\n",
    "        biases = []\n",
    "        for l in self.layers:\n",
    "            if isinstance(l, nn.Linear):\n",
    "                biases.append(l.bias.data.detach())      \n",
    "        return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e3ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDFMesh():\n",
    "  def __init__(self, filename, nsamples):\n",
    "    mesh = trimesh.load(filename)\n",
    "\n",
    "    c0, c1 = mesh.vertices.min(0) - 1e-3, mesh.vertices.max(0) + 1e-3\n",
    "    self.corners = [c0, c1]\n",
    "\n",
    "    # print(\"recentering... \", mesh.vertices[0])\n",
    "    # mesh.vertices -= mesh.vertices.mean(0)\n",
    "    # mesh.vertices /= np.max(np.abs(mesh.vertices))\n",
    "    # mesh.vertices = .5 * (mesh.vertices)\n",
    "    # print(\"done... \", mesh.vertices[0])\n",
    "\n",
    "    #mesh, number_of_points = 500000, surface_point_method='scan', sign_method='normal', scan_count=100, scan_resolution=400, sample_point_count=10000000, normal_sample_count=11, min_size=0\n",
    "    #surface_point_cloud = get_surface_point_cloud(mesh, surface_point_method='sample')\n",
    "    surface_point_cloud = get_surface_point_cloud(mesh, surface_point_method='scan', scan_count=20, scan_resolution=400)\n",
    "    self.coords, self.samples = surface_point_cloud.sample_sdf_near_surface(nsamples//2, use_scans=False, sign_method='normal')\n",
    "    unit_sphere_points = sample_uniform_points_in_unit_sphere(nsamples//2)\n",
    "    samples = surface_point_cloud.get_sdf_in_batches(unit_sphere_points, use_depth_buffer=False)\n",
    "    self.coords = np.concatenate([self.coords, unit_sphere_points]).astype(np.float32)\n",
    "    self.samples = np.concatenate([self.samples, samples]).astype(np.float32)\n",
    "\n",
    "    # self.samples = self.samples[self.coords[:, 0] < 0]\n",
    "    # self.coords = self.coords[self.coords[:, 0] < 0]\n",
    "\n",
    "    print(self.corners, self.coords.shape, self.samples.shape)\n",
    "\n",
    "class SDFDataset(Dataset):\n",
    "    def __init__(self, coords, samples):\n",
    "        super().__init__()\n",
    "        self.samples = torch.from_numpy(samples)\n",
    "        self.coords = torch.from_numpy(coords)\n",
    "\n",
    "    def __len__(self):\n",
    "      return self.coords.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      if index > self.coords.shape[0]: raise IndexError\n",
    "      return self.coords[index,:], torch.tensor([self.samples[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68ba08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_OverfitShape(sdf, config, worker_fn):    \n",
    "    epochs = config['epochs']\n",
    "    learning_rate = config['learning_rate']\n",
    "    batch_size = config['batch_size']\n",
    "    num_batches = config['samples'] / batch_size\n",
    "\n",
    "    model = None\n",
    "    model = MLP(in_features=3, out_features=1, hidden_layers=config['hidden_layers'], hidden_features=config['hidden_features'])\n",
    "        \n",
    "    if USE_GPU:\n",
    "        model.cuda()\n",
    "        \n",
    "    model.train(True)\n",
    "    dataset = SDFDataset(sdf.coords, sdf.samples)\n",
    "    \n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=config['shuffle_dataset'],\n",
    "                            num_workers=0,\n",
    "                            pin_memory=True,\n",
    "                            worker_init_fn=worker_fn)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(lr=learning_rate, params=model.parameters(),\n",
    "                                 weight_decay=config['weight_decay'])\n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    ### Actual training loop    \n",
    "    for e in range(epochs):\n",
    "        count = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_idx, (x_train, y_train) in enumerate(dataloader):\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            count += batch_size\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_train)\n",
    "            loss = loss_func(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        epoch_loss /= num_batches\n",
    "        \n",
    "        ## Logging\n",
    "        if e % 2 == 0:\n",
    "            print('Logging epoch ')\n",
    "            msg = '{}\\tEpoch: {}:\\t[{}/{}]\\tloss: {:.6f}'.format(\n",
    "                \"monke\", e + 1, count, len(dataset), epoch_loss)\n",
    "            print(msg)\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e23d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_files = {\n",
    "    'sphere1'    : 'sphere1.obj',\n",
    "}\n",
    "\n",
    "samples = 128*128*4\n",
    "\n",
    "default_config = dict(\n",
    "    mesh='',\n",
    "    architecture='OverfitShape',\n",
    "    epochs=10,\n",
    "    samples=samples,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.0001,\n",
    "    hidden_layers=3,\n",
    "    hidden_features=16,\n",
    "    shuffle_dataset=False\n",
    ")\n",
    "\n",
    "def plt_weights(sdf):\n",
    "    for w in sdf.weights():\n",
    "        plt.imshow(dump_data(w), cmap = 'gray')\n",
    "        plt.show()\n",
    "        \n",
    "def dump_data(dat):\n",
    "  dat = dat.cpu().detach().numpy()\n",
    "  return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4f74a",
   "metadata": {},
   "source": [
    "# Determinism test\n",
    "\n",
    "Before setting the use_deterministic_algorithms flag to true, one needs to restart the notebook and \n",
    "change a cuda related environment variable: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\n",
    "see https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility for more info.\n",
    "\n",
    "- Enabling this debug workspace for cuda alone does not seem influence determinism of training.\n",
    "- The Dataloader needs to have num_workers=0 or a init fn where np.random.seed is set.\n",
    "- enabling torch.backends.cudnn.benchmark can lead to nondeterminism but in this case didn't\n",
    "- torch.backends.cudnn.deterministic didn't change anything about the training randomness\n",
    "- neither did torch.use_deterministic_algorithms\n",
    "\n",
    "https://github.com/pytorch/pytorch/issues/7068#issuecomment-484918113\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e979a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time: 2021-11-04 17:51:39.560132\n",
      "[TrackedArray([-0.701, -0.701, -0.701]), TrackedArray([0.701, 0.701, 0.701])] (65536, 3) (65536,)\n",
      "Logging epoch \n",
      "monke\tEpoch: 1:\t[65536/65536]\tloss: 0.005563\n",
      "Logging epoch \n",
      "monke\tEpoch: 3:\t[65536/65536]\tloss: 0.000359\n",
      "Logging epoch \n",
      "monke\tEpoch: 5:\t[65536/65536]\tloss: 0.000248\n",
      "Logging epoch \n",
      "monke\tEpoch: 7:\t[65536/65536]\tloss: 0.000218\n",
      "Logging epoch \n",
      "monke\tEpoch: 9:\t[65536/65536]\tloss: 0.000203\n",
      "training done.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed_all(25)\n",
    "torch.manual_seed(25)\n",
    "torch.cuda.manual_seed(25)\n",
    "np.random.seed(25)\n",
    "random.seed(25)\n",
    "\n",
    "default_config['shuffle_dataset']=False\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "   np.random.seed(int(25))\n",
    "\n",
    "print(\"Run Time: {}\".format(dt.datetime.now()))\n",
    "sphere1_sdfmesh = SDFMesh(mesh_files['sphere1'], samples)\n",
    "sphere1 = train_OverfitShape(sphere1_sdfmesh, default_config, _init_fn)\n",
    "print(\"training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e558e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt_weights(sphere1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "228.396px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
